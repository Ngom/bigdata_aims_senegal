{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First let us define the path to the training and test data sets. Just to be absolutely sure, we will check if the path is correct, that the file exists in the path we provided. This is done using the os.path.exists function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_data_filepath='data/train.csv'\n",
    "test_data_filepath='data/test.csv'\n",
    "print 'The path to the training data set is correct: ', os.path.exists(training_data_filepath)\n",
    "print 'The path to the test data set is correct: ', os.path.exists(training_data_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now that we know the files exist, let us first load the training data set to a pandas DataFrame. This DataFrame is just like a table, but with many powerful methods to make analysis on the table very easy. Read more about pandas DataFrame here http://pandas.pydata.org/pandas-docs/stable/dsintro.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_training = pd.read_csv(training_data_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_training.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From the above output we see that, the following features have at least one data missing\n",
    "* 'Age'\n",
    "* 'Cabin'\n",
    "* 'Embarked'\n",
    "* 'Name'\n",
    "* 'Sex'\n",
    "* 'Ticket'\n",
    "##### Question: Why?\n",
    "\n",
    "#### In principle we should try to fill these missing data through interpolation, mean or any other intelligent method. Bur for this excersise let us drop all  the above features with missing data.\n",
    "We use the pandas drop method to drop the columns, hence axis=1, from the training DataFrame. The resulting DataFrame would be a clean training data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_training_clean = df_training.drop(['Age','Cabin','Embarked','Name','Sex','Ticket','Fare'],axis=1)\n",
    "df_training_clean "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our goal here is to train a machine to learn the relationship between different features about the titanic passangers  and their survival chance. Therefore out target is the column * 'Survived' *. We want to drop this column from our DataFrame assign \n",
    "The pop method drops the Survived column from the data frame and assigns it to a variable target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target = df_training_clean.pop('Survived') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_training_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "df_training_clean['Fare'].plot(kind='kde')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let us train a decision tree algorithm using the training data and the corresponding target. We will use the scikit-learn (sklearn) python package. Scikit expects a pure numpy array so we should convert our training DataFrame to numpy array as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "array_training_clean=df_training_clean.values\n",
    "array_target=target.values\n",
    "#the shape method tells us about the rank of the array\n",
    "print 'The shape of training array is: ',array_training_clean.shape \n",
    "print 'The shape of the target array is: ',array_target.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now the training part -  it takes only just three lines!!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import tree #import tree algorithm from scikit-learn\n",
    "#Intitialize the DecisionTreeClassifier algorithm with optional parameters \n",
    "classifier = tree.DecisionTreeClassifier(min_samples_leaf=5, max_depth=4) \n",
    "#use the initialized tree to learn the relationship between \n",
    "#known passanger information, features, and know state of survival \n",
    "classifier.fit(array_training_clean, array_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let us see what the machine will predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#The variable classifier in the above cell contains a tree which has a \n",
    "#knowledge of how passengers features are related to their survival.\n",
    "\n",
    "#Just to have insight, let's see how our decision tree predicts \n",
    "print \"First 5 training target\"\n",
    "print array_target[0:5]\n",
    "print \"Prediction on first 5 training Rows\"\n",
    "print classifier.predict(array_training_clean[0:5,:])\n",
    "\n",
    "# We can see the score, the efficiency of the training as follows\n",
    "print(\"Training Score: \", classifier.score(array_training_clean, array_target))\n",
    "#Since our analysis is simple, we did not attempt to fill the missing data etc.  \n",
    "#the score score is low, in principle with a proper data cleaning etc. \n",
    "# we could get the maximim training score of 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weekend Assignment\n",
    "#### Your task it to do the following - just copy paste the python codes in between the lines and it should work. \n",
    "\n",
    "1. load the test data into pandas DataFrame \n",
    "\n",
    "        df_test = pd.read_csv(test_data_filepath)\n",
    "              \n",
    "2. Check the nature of the test data using the info() method as \n",
    "\n",
    "        df_test.info()    \n",
    "     \n",
    "     Here you will notice that there is missing data for the Fare column for one passenger. \n",
    "     Since we need the same set of features in the training and test data sets, \n",
    "     **we can NOT drop it**. We need therefore to fill it. i) Compute the mean \n",
    "     Fare for different classes, and put them in a dictionary ii) get the rows whose\n",
    "     Fare is missing iii) fill the missing data according to the class the passanger is in \n",
    "\n",
    "        i) mean_fare_by_pclass = df_test[['Pclass','Fare']].groupby(['Pclass']).agg('mean')['Fare']\n",
    "    \n",
    "        ii) fare_given_pclass=df_test['Pclass'].apply(lambda x: mean_fare_by_pclass[x])\n",
    "    \n",
    "        iii) df_test['Fare'].fillna(fare_given_pclass,inplace=True)\n",
    "    \n",
    "3. Similar to what we did for the training data, drop the columns \n",
    "    ['Age','Cabin','Embarked','Name','Sex','Ticket'] as \n",
    "\n",
    "        df_test_clean = df_test.drop(['Age','Cabin','Embarked','Name','Sex','Ticket'],axis=1)\n",
    "                    \n",
    "4. Convert the test DataFrame to numpy array \n",
    "\n",
    "        array_test_clean = df_test_clean.values\n",
    "               \n",
    "5. Predict the survival of passengers using the tree we trained as\n",
    "\n",
    "        survival_prediction = classifier.predict(array_test_clean)     \n",
    "          \n",
    "6. Save the prediction to a file. If you want, you can submit this file in Kaggle page and get your score \n",
    "\n",
    "        with open('prediction.csv', 'w') as csvfile:    \n",
    "            for survived in survival_prediction:\n",
    "                 csvfile.write(\"{}\\n\".format(survived)) \n",
    "    \n",
    "7. **BONUS:** Visualize the result. Be creative :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
